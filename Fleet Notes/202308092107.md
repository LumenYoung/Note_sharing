---
aliases: [Thesis Proposal newest, thesis]
tags: [thesis/project, review]
title: "202308092107"
date created: Wednesday, August 9th 2023, 9:07:09 pm
date modified: Tuesday, September 5th 2023, 1:03:23 pm
---

## Thesis Proposal 3

This proposal is inspired by the
- [[RoboCat|RoboCat]]
- [[VoxPoser]]
- [[RT-2]]
- [[RoboAgent|RoboAgent]]
- [[Voyager]]

## Idea: [[Voyager]] like autonomous agent on manipulation

Attempts to use LLMs and VLMs for robot manipulation task typically rely on *training/finetuning on large datasets* or *additional path planning scheme* to accomplish different kinds of manipulation tasks.

Given the paucity of the robot manipulation datasets, the former approach is potential limited to only small subsets of robot that have teleOp dataset available and the latter one can only leverage the existing reasoning power of the LLM, not able to compose and create more complex behaviors from primitives.

We argue that in order to develop an agent that can really accommodate to be really general agent for manipulation tasks, it is more important for the agent to be able to **learn from the environmental feedback** and accumulate complex skills from **trial-and-errors with simple premitives**.

[[Voyager]] provides an example design for such agent. They built an autonomous agent in Minecraft that is capable of exploring and accumulate different skills. Their study shows the potential of such approach in an idea environment, where the failure feedback is provided prefectly and accurately in the Minecraft simulator.

To implement this idea, we want to develop the [[Language agent]] to learn how to drive low-level api/command to act in real world using systematic way of reasoning like [[React]] and [[Tree of Thoughs]]. The LLM issue command and interpret observation, the observation from intervention is used to train the LLM to learn robot action as a language.

### Challenges

One of the requirement of our idea is that the robot can pick **generalizable knowledge from simple operations**, which can then contribute to the establishment of more complexed skill, it is vital for the robot to **distinguish part of the informatiom that should be transfered from irrelevant parts**.

In this perspective, [[explicitly learnt causal structure could be helpful in providing feedbacks that are relevant]]. And for the agent to explore the action space, they can be aided by an systematic tree structure search

When we want the robot to automatically pick **generalizable knowledge** from simple operations.

### Experiments

There should be difference in the visual perception pipeline as well. For the visual process to work well, we need to also incorporate the visual token into the LLM’s prompt. Work like ==*Planting a SEED of Vision in Large Language Model*== could be potentially helpful. If the structure of the ReAct should be used, the observation should contain the current visual observation as well as the difference between observations. Also, it is possible to [[Use video backbone as the vision backbone]].

Our agent should be similar to the [[Voyager]], an agent that can automatically explore and expand its skill library.

The causality model should be used in this case for the validation procedure. How should the two rungs of causality be integrated here? Intervention and Counterfactural.

It is important to note [[The potential problem of lacking the 3D prior understanding]], which might lead to failed understanding on the egocentric visual input. Generally it is better currently to have static camera setup rather than the egocentric one.

It is also important that the visual token **should preserve the current scene as well as the change**, since the effect of intervention should be explicitly observable.

The paper *Causal Reasoning and Large Language Models: Opening a New Frontier for Causality* show that LLM can do many causal inference, despite occasionally occurred failures that are not fully explainable. They also conclude that although such unexplainable faliure happenes, it is very rare. This conclusion seems to indicate the possibilty for LLM to provide causal-based feedback.

### Design choices

1. [[The skill library should be a collection of accumulated language model program]]
2. [[An availability heuristic is a mental shortcut (usually used unconsciously) that relies on the data that comes to mind first (or most easily; Kahneman, 2011).]]
3. Blip can track attention field in the image, the [[visual percetpion can leverage BLIP’s localization ability to interact with LLM in text]].
4. Also, [[VLM-based VQA can also be helpful in reasoning the temporal events]]. This could enable a more general feedback. ==validation needed==
5. For the prompting scheme, [princeton blog](https://princeton-nlp.github.io/SocraticAI/) introduced a socratic method for free-form prompting
6. [[The choice of the LLM for our agent]] , Code LLAMA and GPT-4 (for cases Code LLAMA fails).
7. Design of visual perception integration is also a concern in our system.
8. The action space in TOT should contain: command, backtrack, create.

[[In my opinion, interleaving modality prompt is the best way to combine visual and text]].

Additional docstring after feedback will help decide between tools.

%% 3. For visual token integration  
	1. [[VIMA]] provides interleaving visual, text  
	2. *Planting a SEED of Vision in Large Language Model* offers another scheme for that. %%

#### Visual perception design and choices

Many different model

[mplug-owl-llama-7b](https://huggingface.co/MAGAer13/mplug-owl-llama-7b)

[WizardLM](https://github.com/nlpxucan/WizardLM) uses [Evol-instruct](https://arxiv.org/abs/2304.12244) a great automatic prompting scheme to finetune LLAMA with automatically generated instructions.

### Questions I have

- How to choose about the visual backbone?

## ToDo

now

- [ ] read about [[Tree of Thought]] (possiblely [[ReAct]] and [[Reflexion]]), see 1) what is needed to generate semantically rich feedback, 2) which one seems more suitable to incorporate with causal discovery and inference, 3) how themselves can be incorporated with each others.

later

- [ ] **rlbench** and **robomimic** as the benchmark for the evaluation.
- [ ] **sapien** as the simulator
- [ ] 23-08-22 09:55 Add [[VIMA]] into the list as it is a new prompt-based approach.
- [x] 23-08-15 08:40 我发现 [[RoboAgent|RoboAgent]] 可以提供一个很好的 dataset，同样有不错的 generalization ability。这个应该作为很重要的一部分。

- fold
	- [x] Finish the workshop from Shunyu Yao.
	- [x] have a read on [this blog](https://princeton-nlp.github.io/SocraticAI/) on socratic method prompting

## Output

[[Both RoboCat and VoxPoser show self-improvment ability]]

## Important aspects

Traing aspect:

```dataview
table trained as "train?", dataset, training_resource as "resource", reproducibility as "reprod?"
from #MTpaper 
```

Metric aspect:

```dataview
table baseline, metric_baseline as "metrics", high_success_rate as "reliable?", open_sourced as "open sourced?"
from #MTpaper 
```

Action representation:

```dataview
table traj_rep
from #MTpaper 
```

Perception:

```dataview
table perception_model
from #MTpaper 
```

## References

[[RoboCat trains on new skill independently to avoid Catastrophic forgetting]]

Idea of low priority: [[Idea - LLM directly issue action token |LLM directly issue action token]]

[1]
```
@misc{kicimanCausalReasoningLarge2023,
	title = {Causal {Reasoning} and {Large} {Language} {Models}: {Opening} a {New} {Frontier} for {Causality}},
	shorttitle = {Causal {Reasoning} and {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2305.00050},
	doi = {10.48550/arXiv.2305.00050},
	abstract = {The causal capabilities of large language models (LLMs) is a matter of significant debate, with critical implications for the use of LLMs in societally impactful domains such as medicine, science, law, and policy. We further our understanding of LLMs and their causal implications, considering the distinctions between different types of causal reasoning tasks, as well as the entangled threats of construct and measurement validity. LLM-based methods establish new state-of-the-art accuracies on multiple causal benchmarks. Algorithms based on GPT-3.5 and 4 outperform existing algorithms on a pairwise causal discovery task (97\%, 13 points gain), counterfactual reasoning task (92\%, 20 points gain), and actual causality (86\% accuracy in determining necessary and sufficient causes in vignettes). At the same time, LLMs exhibit unpredictable failure modes and we provide some techniques to interpret their robustness. Crucially, LLMs perform these causal tasks while relying on sources of knowledge and methods distinct from and complementary to non-LLM based approaches. Specifically, LLMs bring capabilities so far understood to be restricted to humans, such as using collected knowledge to generate causal graphs or identifying background causal context from natural language. We envision LLMs to be used alongside existing causal methods, as a proxy for human domain knowledge and to reduce human effort in setting up a causal analysis, one of the biggest impediments to the widespread adoption of causal methods. We also see existing causal methods as promising tools for LLMs to formalize, validate, and communicate their reasoning especially in high-stakes scenarios. In capturing common sense and domain knowledge about causal mechanisms and supporting translation between natural language and formal methods, LLMs open new frontiers for advancing the research, practice, and adoption of causality.},
	urldate = {2023-08-31},
	publisher = {arXiv},
	author = {Kıcıman, Emre and Ness, Robert and Sharma, Amit and Tan, Chenhao},
	month = may,
	year = {2023},
	note = {arXiv:2305.00050 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, Statistics - Methodology, Computer Science - Computers and Society},
	annote = {Comment: 42 pages, 5 figures, working paper (minor changes in v2 to fix typos)},
	file = {arXiv Fulltext PDF:/home/yang/Zotero/storage/SLPDLGDA/Kıcıman et al. - 2023 - Causal Reasoning and Large Language Models Openin.pdf:application/pdf;arXiv.org Snapshot:/home/yang/Zotero/storage/RSNI7U3G/2305.html:text/html},
}
```